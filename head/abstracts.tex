%\begingroup
%\let\cleardoublepage\clearpage


% English abstract
\cleardoublepage
\chapter*{Abstract}
\markboth{Abstract}{Abstract}
\addcontentsline{toc}{chapter}{Abstract (English/Français)} % adds an entry to the table of contents
% put your text here
Recent advancements in deep learning have revolutionized 3D computer vision, enabling the extraction of intricate 3D information from 2D images and video sequences. This thesis explores the application of deep learning in three crucial challenges of 3D computer vision: Depth Estimation, Novel View Synthesis, and Simultaneous Localization and Mapping (SLAM).

\vspace{2ex}
In the first part of the study, a self-supervised deep-learning method for depth estimation using a structured-light camera is proposed. Our method utilizes optical flow for improved edge preservation and reduced over-smoothing. In addition, we propose fusing depth maps from multiple video frames to enhance overall accuracy, particularly in occluded areas. Further, we demonstrate that these fused depth maps can be used for self-supervision to further improve the performance of a single-frame depth estimation network. Our models outperform state-of-the-art methods on both synthetic and real datasets.

\vspace{2ex}
In the second part of the study, a generalizable photorealistic novel view synthesis method based on neural radiance fields (NeRF) is introduced. Our approach employs a geometry reasoner and a renderer to generate high-quality images from novel viewpoints. The geometry reasoner constructs cascaded cost volumes for each nearby source view, while the renderer utilizes a Transformer-based attention mechanism to integrate information from these cost volumes and render detailed images using volume rendering techniques. This architecture enables sophisticated occlusion reasoning and allows our method to render competitive results with per-scene optimized neural rendering methods while significantly reducing computational costs. Our experiments demonstrate superiority over state-of-the-art generalizable neural rendering models on various synthetic and real datasets.

\vspace{2ex}
In the last part of the study, an efficient implicit neural representation method for dense visual SLAM is presented. The method reconstructs the scene representation while simultaneously estimating the camera position in a sequential manner from RGB-D frames with unknown poses. We incorporate recent advances in NeRF into the SLAM system, achieving both high accuracy and efficiency. The scene representation consists of multi-scale axis-aligned perpendicular feature planes and shallow decoders that decode the interpolated features into Truncated Signed Distance Field (TSDF) and RGB values. Extensive experiments on standard datasets demonstrate that our method outperforms state-of-the-art dense visual SLAM methods by more than 50\% in 3D reconstruction and camera localization while running up to 10 times faster and eliminating the need for pre-training.

\vspace{2ex}
\textbf{Keywords:} deep learning, 3D computer vision, depth estimation, novel view synthesis, neural radiance fields (NeRF), scene reconstruction, simultaneous localization and mapping (SLAM)

% French abstract
\begin{otherlanguage}{french}
\cleardoublepage
\chapter*{Résumé}
\markboth{Résumé}{Résumé}
% put your text here
Les récentes avancées dans le domaine de l'apprentissage profond ont révolutionné la vision 3D par ordinateur, permettant l'extraction d'informations 3D complexes à partir d'images 2D et de séquences vidéo. Cette thèse explore l'application de l'apprentissage profond à trois défis cruciaux de la vision 3D par ordinateur: L'estimation de la profondeur (Depth Estimation), la synthèse de nouvelles vues (Novel View Synthesis) et la localisation et la cartographie simultanées (SLAM).

\vspace{2ex}
Dans la première partie de l'étude, une méthode d'apprentissage profond auto-supervisée pour l'estimation de la profondeur à l'aide d'une caméra à lumière structurée est proposée. Notre méthode utilise le flux optique pour une meilleure préservation des bords et un lissage excessif réduit. En outre, nous proposons de fusionner les cartes de profondeur de plusieurs images vidéo afin d'améliorer la précision globale, en particulier dans les zones occultées. En outre, nous démontrons que ces cartes de profondeur fusionnées peuvent être utilisées pour l'auto-supervision afin d'améliorer encore les performances d'un réseau d'estimation de profondeur à image unique. Nos modèles sont plus performants que les méthodes les plus récentes sur des ensembles de données synthétiques et réelles.


\vspace{2ex}
Dans la deuxième partie de l'étude, une méthode généralisable de synthèse photoréaliste de nouvelles vues basée sur les champs de radiance neuronaux (NeRF) est introduite. Notre approche utilise un raisonneur géométrique et un moteur de rendu pour générer des images de haute qualité à partir de nouveaux points de vue. Le raisonneur géométrique construit des volumes de coûts en cascade pour chaque vue source proche, tandis que le moteur de rendu utilise un mécanisme d'attention basé sur un transformateur pour intégrer les informations de ces volumes de coûts et rendre des images détaillées en utilisant des techniques de rendu de volume. Cette architecture permet un raisonnement sophistiqué en matière d'occlusion et permet à notre méthode d'obtenir des résultats compétitifs par rapport aux méthodes de rendu neuronal optimisées par scène, tout en réduisant considérablement les coûts de calcul. Nos expériences démontrent la supériorité de notre méthode par rapport aux modèles de rendu neuronal généralisables les plus récents sur divers ensembles de données synthétiques et réelles.

\vspace{2ex}
Dans la dernière partie de l'étude, une méthode efficace de représentation neuronale implicite pour le SLAM visuel dense est présentée. La méthode reconstruit la représentation de la scène tout en estimant simultanément la position de la caméra de manière séquentielle à partir d'images RVB-D dont les poses sont inconnues. Nous intégrons les récentes avancées en matière de NeRF dans le système SLAM, ce qui permet d'obtenir une précision et une efficacité élevées. La représentation de la scène se compose de plans de caractéristiques perpendiculaires alignés sur plusieurs échelles et de décodeurs peu profonds qui décodent les caractéristiques interpolées en champ de distance signé tronqué (TSDF) et en valeurs RVB. Des expériences approfondies sur des ensembles de données standard démontrent que notre méthode surpasse les méthodes SLAM visuelles denses de plus de 50 \% dans la reconstruction 3D et la localisation de la caméra, tout en fonctionnant jusqu'à 10 fois plus vite et en éliminant le besoin de pré-entraînement.

\vspace{2ex}
\textbf{Mots-clés:} apprentissage profond, vision par ordinateur 3D, estimation de la profondeur, synthèse de vues nouvelles, champs de radiance neuronaux (NeRF), reconstruction de scènes, localisation et cartographie simultanées (SLAM)

\end{otherlanguage}


%\endgroup			
%\vfill
