\chapter{Conclusion and Future Work} \label{sec:chapter5}

\section{Conclusion}

In this thesis, we have made significant contributions to the fields of 3D computer vision and scene understanding through the introduction of three novel approaches. Firstly, we propose a novel approach to improve the accuracy of monocular depth estimation from depth sensor raw data. Subsequently, we introduce a new generalizable method that enhances the quality of synthesized images from novel camera poses. Finally, we introduce an efficient dense visual SLAM system that outperforms state-of-the-art methods in both accuracy and efficiency.

 We have presented DepthInSpace in \hyperref[sec:chapter2]{Chapter~\ref{sec:chapter2}} which represents a significant leap forward in the accurate estimation of depth from structured-light sensor data. By integrating optical flow and harnessing information from multiple video frames within a self-supervised framework, DepthInSpace enhances depth estimation accuracy and outperforms existing methods, as evidenced by qualitative and quantitative evaluations across diverse datasets, including synthetic and real-world scenes.

Moving on to our second contribution in \hyperref[sec:chapter3]{Chapter~\ref{sec:chapter3}}, GeoNeRF stands out as a pioneering generalizable method for novel view synthesis. This approach not only achieves state-of-the-art image quality for complex scenes but also eliminates the need for per-scene optimization. Leveraging recent advancements in multi-view architectures and radiance fields, GeoNeRF constructs cascaded cost volumes for source views, which are then aggregated through an attention-based network for synthesizing images from novel poses. Furthermore, we propose promising avenues for future research, suggesting that the incorporation of advanced algorithms to dynamically select nearby views or an adaptive approximation of the optimal number of required cost volumes could further enhance the versatility and efficiency of GeoNeRF.

Lastly, our third contribution in \hyperref[sec:chapter4]{Chapter~\ref{sec:chapter4}}, ESLAM, introduces a top-tier dense visual SLAM by leveraging Neural Radiance Fields to improve both speed and accuracy. Through the innovative replacement of voxel grid representation with axis-aligned feature planes and the adoption of Truncated Signed Distance Field for scene geometry modeling, ESLAM showcases remarkable advancements in reconstruction and localization accuracy. Notably, our experiments validate that ESLAM improves existing methods' accuracy significantly while running up to one order of magnitude faster.

 Collectively, these three contributions not only advance the state-of-the-art in their respective domains, but also set the stage for further research and applications, demonstrating the transformative potential of our innovative approaches in the broader landscape of 3D computer vision research.

\section{Future Work and Recent Advances in Related Work}

Considering the advancements highlighted in this thesis, numerous exciting opportunities for future research emerge within the domains of depth estimation, novel view synthesis, and dense visual SLAM. It is worth noting that due to the rapid expansion of research in these areas, there are already several concurrent or inspired works documented in the literature as of the time of this writing. This section offers a concise overview of potential extensions, both existing and prospect.


To enhance \textbf{DepthInSpace}, there is potential for additional investigation into expanding the self-supervised framework to include active stereo. This involves utilizing a stereo camera to capture the illuminated pattern, which contributes supplementary information for the algorithm to reason about geometry and occlusion. Notably, this approach could allow for the adoption of a sparser projection pattern, offering advantages in terms of power consumption and efficiency.

An additional avenue of research involves addressing the constraints imposed by the current dataset. Despite our exploration of various synthetic datasets and the evaluation of our method on real-world scenes, the absence of an extensive real dataset remains a limiting factor for the effectiveness of our proposed approach. A potential strategy to alleviate this limitation is to adapt the model to leverage recent advancements in conventional monocular depth estimation. Utilizing large datasets, such as~\cite{ranftl2020towards}, in this domain could provide robust prior information for the network, helping to mitigate the aforementioned issue to some extent.

An alternative enhancement to boost the generalizability of DepthInSpace to out-of-distribution depths involves substituting the single-frame depth regressor network with a cost-volume-based depth estimator network. This modification makes the network indifferent to the absolute values of depths or disparities. Consequently, the network becomes capable of functioning on novel datasets where depth values exhibit a significant shift compared to those in the training sets.