\chapter{GeoNeRF: Generalizing NeRF with Geometry Priors}

\section{Chapter Introduction} \label{sec:chapter3}

Novel view synthesis is a long-standing task in computer vision and computer graphics. Neural Radiance Fields (NeRF)~\cite{mildenhall2020nerf} made a significant impact on this research area by implicitly representing the 3D structure of the scene and rendering high-quality novel images. Our work addresses the main drawback of NeRF, which is the requirement to train from scratch for every scene separately. The per-scene optimization of NeRF is lengthy and requires densely captured images from each scene.

Approaches like pixelNeRF~\cite{yu2021pixelnerf}, GRF~\cite{trevithick2021grf}, MINE~\cite{li2021mine}, SRF~\cite{chibane2021stereo}, IBRNet~\cite{wang2021ibrnet}, MVSNeRF~\cite{chen2021mvsnerf}, and recently introduced NeRFormer~\cite{reizenstein2021common} address this issue and generalize NeRF rendering technique to unseen scenes. The common motivation behind such methods is to condition the NeRF renderer with features extracted from source images from a set of nearby views. Despite the generalizability of these models to new scenes, their understanding of the scene geometry and occlusions is limited, resulting in undesired artifacts in the rendered outputs. MVSNeRF~\cite{chen2021mvsnerf} constructs a low-resolution 3D cost volume inspired by MVSNet~\cite{yao2018mvsnet}, which is widely used in the Multi-View Stereo research, to condition and generalize the NeRF renderer. However, it has difficulty rendering detailed images and does not deal with occlusions in a scene. In this work, we take MVSNeRF as a baseline and propose the following improvements.

\begin{itemize}
\item We introduce a geometry reasoner in the form of cascaded cost volumes~(Section~\ref{sec:c3_geometry}) and train it in a semi-supervised fashion~(Section~\ref{sec:c3_loss}) to obtain fine and high-resolution priors for conditioning the renderer.

\item We combine an attention-based model which deals with information coming from different source views at any point in space, by essence permutation invariant, with an auto-encoder network which aggregates information along a ray, leveraging its strong Euclidean and ordering structure~(Section~\ref{sec:c3_renderer}).

\item Thanks to the symmetry and generalizability of our geometry reasoner and renderer, we detect and exclude occluded views for each point in space and use the remaining views for processing that point~(Section~\ref{sec:c3_renderer}). 

\end{itemize}

In addition, with a slight modification to the architecture, we propose an alternate model that takes RGBD images (RGB+Depth) as input and exploits the depth information to improve its perception of the geometry~(Section~\ref{sec:c3_rgbd_method}).

Concurrent to our work, the followings also introduce a generalizable NeRF: RGBD-Net~\cite{nguyen2021rgbd} builds a cost volume for the target view instead of source views, NeuralMVS\cite{rosu2021neuralmvs} proposes a coarse to fine approach to increase speed, and NeuRay~\cite{liu2021neural} proposes a method to deal with occlusions.
